{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaA4ccjTR4uV"
      },
      "outputs": [],
      "source": [
        "# Init workspace\n",
        "!mkdir dataset\n",
        "\n",
        "# Download dataset and extract it\n",
        "!gdown 111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V\n",
        "!mv imagenet-a.tar ./dataset\n",
        "!tar -xf ./dataset/imagenet-a.tar\n",
        "!mv imagenet-a ./dataset\n",
        "\n",
        "# Cleanup\n",
        "!rm ./dataset/imagenet-a.tar\n",
        "\n",
        "# (optional) Upgrading pytorch for the latest augmentation functions\n",
        "#!pip install --upgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "import json\n",
        "from os.path import basename, join\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "import re\n",
        "from contextlib import nullcontext\n",
        "from typing import Union\n",
        "from copy import deepcopy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ECdvhkFCpxci"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xMgaZ3ON9hNd"
      },
      "outputs": [],
      "source": [
        "# Use cuda if available\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SIZE = (384, 384)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lAfAfJw9XBdX"
      },
      "outputs": [],
      "source": [
        "def load_imagenet_a_labels() -> list[str]:\n",
        "\n",
        "    imagenet_a = \"./dataset/imagenet-a\"\n",
        "\n",
        "    with open(join(imagenet_a, \"README.txt\"), \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    pattern = re.compile(r\"n\\d{8}\\s(.+)\")\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for label in [line.strip() for line in lines if pattern.match(line)]:\n",
        "        label = label.strip()\n",
        "        label = label.split(\" \")\n",
        "        label = \" \".join(label[1:])\n",
        "\n",
        "        labels.append(label)\n",
        "\n",
        "    return labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "scjsACtS7Mzz"
      },
      "outputs": [],
      "source": [
        "def load_model_labels() -> list[str]:\n",
        "\n",
        "    url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
        "    path = Path(basename(url))\n",
        "\n",
        "    # Check if labels file already exists\n",
        "    if not path.exists():\n",
        "        response = requests.get(url)\n",
        "        path.write_text(response.text)\n",
        "\n",
        "    # Load labels\n",
        "    with open(path, \"r\") as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sH4oeOPsfwLu"
      },
      "outputs": [],
      "source": [
        "def merge_labels() -> dict:\n",
        "\n",
        "    # Map imagenet's labels with model's labels\n",
        "    imagenet_a_labels = load_imagenet_a_labels()\n",
        "    model_labels = load_model_labels()\n",
        "\n",
        "    labels = {}\n",
        "\n",
        "    for imagenet_a_index, item in enumerate(imagenet_a_labels):\n",
        "\n",
        "        model_index = model_labels.index(item)\n",
        "\n",
        "        labels[item] = {\n",
        "            \"imagenet-a\": imagenet_a_index,\n",
        "            \"model\": model_index\n",
        "        }\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mZ4Mo02l8cqQ"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name: str = \"google/vit-base-patch16-384\") -> ViTForImageClassification:\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    return ViTForImageClassification.from_pretrained(model_name).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ut7hOuKqfnct"
      },
      "outputs": [],
      "source": [
        "def load_dataset(resize: bool = True) -> torch.utils.data.dataloader.DataLoader:\n",
        "\n",
        "    imagenet_a = \"./dataset/imagenet-a/\"\n",
        "\n",
        "    # Prepare data transformations for the train loader\n",
        "    transforms = [] if not resize else [T.Resize(SIZE)]\n",
        "    transforms.append(T.ToTensor())\n",
        "    transform = T.Compose(transforms)\n",
        "\n",
        "    # Load data\n",
        "    imagenet_a_dataset = torchvision.datasets.ImageFolder(root=imagenet_a, transform=transform)\n",
        "    return torch.utils.data.DataLoader(imagenet_a_dataset, 1, shuffle=True, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bk0WB8NHXXlQ"
      },
      "outputs": [],
      "source": [
        "def classify(model: ViTForImageClassification, img: torch.Tensor, no_grad: bool = True) -> dict:\n",
        "\n",
        "    # Use GPU if available\n",
        "    img = img.to(DEVICE)\n",
        "\n",
        "    # Perform inference\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad() if no_grad else nullcontext():\n",
        "        outputs = model(img)\n",
        "\n",
        "    # Extract probabilities from model's output logits\n",
        "    results = torch.nn.functional.softmax(outputs.logits, dim=-1).squeeze()\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def elaborate_results(results: torch.Tensor) -> Union[dict, list]:\n",
        "\n",
        "    # Load model's labels\n",
        "    model_labels = load_model_labels()\n",
        "\n",
        "    # ImageNet-A's labels\n",
        "    imagenet_a_labels = load_imagenet_a_labels()\n",
        "\n",
        "    if len(results.shape) == 1:\n",
        "        results = [results]\n",
        "\n",
        "    # Process results\n",
        "    final_results = []\n",
        "\n",
        "    for result in results:\n",
        "\n",
        "        item_results = {\n",
        "            \"predicted\": {},\n",
        "            \"results\": {}\n",
        "        }\n",
        "\n",
        "        predicted = None\n",
        "\n",
        "        for index, probability in enumerate(result):\n",
        "\n",
        "            if model_labels[index] not in imagenet_a_labels:\n",
        "                continue\n",
        "\n",
        "            item_results[\"results\"][index] = {\n",
        "                \"index\": index,\n",
        "                \"label\": model_labels[index],\n",
        "                \"probability\": probability.item()\n",
        "            }\n",
        "\n",
        "            if predicted is None or predicted[\"probability\"] < probability.item():\n",
        "                predicted = item_results[\"results\"][index]\n",
        "\n",
        "        item_results[\"predicted\"] = predicted\n",
        "\n",
        "        final_results.append(item_results)\n",
        "\n",
        "    return final_results if len(final_results) > 1 else final_results[0]\n"
      ],
      "metadata": {
        "id": "iLeoCaOmWG2u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6SRcSAf9IJEv"
      },
      "outputs": [],
      "source": [
        "# Load model (only once)\n",
        "model = load_model()\n",
        "\n",
        "# Load data (only once)\n",
        "data_loader = load_dataset()\n",
        "\n",
        "# Extract merged labels\n",
        "merged_labels = merge_labels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrXGkChUYXHS"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model (Accuracy: 18.37 %)\n",
        "accuracy = 0\n",
        "\n",
        "for index, img in enumerate(data_loader):\n",
        "\n",
        "    # Get model prediction\n",
        "    results = classify(model=model, img=img[0])\n",
        "    results = elaborate_results(results=results)\n",
        "    predicted, results = results[\"predicted\"], results[\"results\"]\n",
        "\n",
        "    # Check if the predicted label exists inside the dataset labels\n",
        "    if predicted[\"label\"] in merged_labels:\n",
        "\n",
        "        merged_label = merged_labels[predicted[\"label\"]]\n",
        "\n",
        "        # Check if the prediction was correct\n",
        "        if merged_label[\"imagenet-a\"] == img[1].item():\n",
        "            accuracy = accuracy + 1\n",
        "\n",
        "    print(f\"Image {index+1} / {len(data_loader)} | Accuracy: {round((accuracy / (index + 1)) * 100, 2)}% ({accuracy} / {index + 1})\")\n",
        "\n",
        "accuracy = accuracy / len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzaEQC-_dzji"
      },
      "outputs": [],
      "source": [
        "# Supponendo che load_dataset, classify_image, merged_labels e il modello siano definiti altrove\n",
        "accuracy_before = 0\n",
        "accuracy_after = 0\n",
        "\n",
        "# Load model (only once)\n",
        "model = load_model()\n",
        "original_model = deepcopy(model)\n",
        "\n",
        "# Extract merged labels\n",
        "merged_labels = merge_labels()\n",
        "\n",
        "data_loader = load_dataset(resize=False)\n",
        "\n",
        "# transformation = T.Compose([\n",
        "#         T.Resize((500, 500)),\n",
        "#         T.CenterCrop((384, 384)) ])\n",
        "\n",
        "transforms = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(384, 384), antialias=True),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "resize_transformation = T.Compose([ T.Resize((384, 384)) ])\n",
        "\n",
        "# Salva lo stato iniziale del modello\n",
        "initial_state = model.state_dict().copy()\n",
        "\n",
        "for index, img in enumerate(data_loader):\n",
        "    # Ripristina lo stato iniziale del modello\n",
        "    model = deepcopy(original_model)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    # Azzera i gradienti prima di calcolare i nuovi\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Immagine ridimensionata (384x384)\n",
        "    img1 = resize_transformation(img[0])\n",
        "    # Immagini con augmentation\n",
        "    img2 = transforms(img[0])\n",
        "    img3 = transforms(img[0])\n",
        "    img4 = transforms(img[0])\n",
        "\n",
        "    # Concatena immagini\n",
        "    imgs = [img1, img2, img3, img4]\n",
        "    input = torch.cat(imgs, dim=0)\n",
        "\n",
        "    # Classificazione dell'immagine 1 prima delle augmentation\n",
        "    results = classify(model=model, img=img1)\n",
        "    results = elaborate_results(results=results)\n",
        "    predicted, results = results[\"predicted\"], results[\"results\"]\n",
        "\n",
        "    # Aggiorna accuracy della classificazione senza augmentation\n",
        "    if predicted[\"label\"] in merged_labels:\n",
        "        merged_label = merged_labels[predicted[\"label\"]]\n",
        "        # Check if the prediction was correct\n",
        "        if merged_label[\"imagenet-a\"] == img[1].item():\n",
        "            accuracy_before += 1\n",
        "    predicted_before = predicted[\"label\"]\n",
        "\n",
        "    # Calcola gli output delle immagini\n",
        "    output = model(input.to(DEVICE))\n",
        "\n",
        "    # Combina le probabilità delle immagini\n",
        "    probabilities = torch.nn.functional.softmax(output.logits, dim=-1).squeeze().to(DEVICE)\n",
        "\n",
        "    # Calcolo entropia\n",
        "    marginal = torch.mean(probabilities, dim=0).to(DEVICE)\n",
        "    entropy = -torch.sum(marginal * torch.log(marginal)).to(DEVICE)\n",
        "    entropy.backward()\n",
        "\n",
        "    # Gradient step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Classificazione dell'immagine 1 dopo le augmentation\n",
        "    results = classify(model=model, img=img1)\n",
        "    results = elaborate_results(results=results)\n",
        "    predicted, results = results[\"predicted\"], results[\"results\"]\n",
        "\n",
        "    #print(probabilities1 == probabilities2)\n",
        "    # Aggiorna accuracy della classificazione con augmentation\n",
        "    if predicted[\"label\"] in merged_labels:\n",
        "        merged_label = merged_labels[predicted[\"label\"]]\n",
        "        if merged_label[\"imagenet-a\"] == img[1].item():\n",
        "            accuracy_after += 1\n",
        "\n",
        "    print(f\"Image {index + 1} / {len(data_loader)} | Accuracy before: {round((accuracy_before / (index + 1)) * 100, 1)}% ({accuracy_before} / {index + 1}) | Accuracy after: {round((accuracy_after / (index + 1)) * 100, 1)}% ({accuracy_after} / {index + 1})\", \"\\t --> Predicted:\", predicted_before, \"/\", predicted[\"label\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}