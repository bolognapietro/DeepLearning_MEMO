{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Init workspace\n",
        "!mkdir dataset\n",
        "\n",
        "# Download dataset and extract it\n",
        "!gdown 111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V\n",
        "!mv imagenet-a.tar ./dataset\n",
        "!tar -xf ./dataset/imagenet-a.tar\n",
        "!mv imagenet-a ./dataset\n",
        "\n",
        "# Cleanup\n",
        "!rm ./dataset/imagenet-a.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaA4ccjTR4uV",
        "outputId": "581f3aeb-7e87-4ef6-cd20-a232c30e4f20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V\n",
            "From (redirected): https://drive.google.com/uc?id=111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V&confirm=t&uuid=08d06f71-a2aa-4f84-88f3-68f4feaff201\n",
            "To: /content/imagenet-a.tar\n",
            "100% 688M/688M [00:04<00:00, 157MB/s]\n",
            "mv: cannot move 'imagenet-a' to './dataset/imagenet-a': Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrading pytorch for the latest augmentation functions\n",
        "#!pip install --upgrade torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "yrBodk6pO738"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "import json\n",
        "from os.path import basename, join\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "YwWm7RyV4bci"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SIZE = (384, 384)"
      ],
      "metadata": {
        "id": "xMgaZ3ON9hNd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_imagenet_a_labels() -> list:\n",
        "\n",
        "    imagenet_a = \"./dataset/imagenet-a\"\n",
        "\n",
        "    with open(join(imagenet_a, \"README.txt\"), \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    pattern = re.compile(r\"n\\d{8}\\s(.+)\")\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for index, label in enumerate([line.strip() for line in lines if pattern.match(line)]):\n",
        "        label = label.strip()\n",
        "        label = label.split(\" \")\n",
        "        label = \" \".join(label[1:])\n",
        "\n",
        "        labels.append(label)\n",
        "\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "lAfAfJw9XBdX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_labels() -> list[str]:\n",
        "\n",
        "    url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
        "    path = Path(basename(url))\n",
        "\n",
        "    # Check if labels file already exists\n",
        "    if not path.exists():\n",
        "        response = requests.get(url)\n",
        "        path.write_text(response.text)\n",
        "\n",
        "    # Load labels\n",
        "    with open(path, \"r\") as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "scjsACtS7Mzz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_labels() -> dict:\n",
        "\n",
        "    imagenet_a_labels = load_imagenet_a_labels()\n",
        "    model_labels = load_model_labels()\n",
        "\n",
        "    labels = {}\n",
        "\n",
        "    for imagenet_a_index, item in enumerate(imagenet_a_labels):\n",
        "\n",
        "        model_index = model_labels.index(item)\n",
        "\n",
        "        labels[item] = {\n",
        "            \"imagenet-a\": imagenet_a_index,\n",
        "            \"model\": model_index\n",
        "        }\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "sH4oeOPsfwLu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name: str = \"google/vit-base-patch16-384\") -> ViTForImageClassification:\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    model = ViTForImageClassification.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mZ4Mo02l8cqQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(resize: bool = True):\n",
        "\n",
        "    imagenet_a = \"./dataset/imagenet-a/\"\n",
        "\n",
        "    # Prepare data transformations for the train loader\n",
        "    transforms = [] if not resize else [T.Resize(SIZE)]\n",
        "    transforms.append(T.ToTensor())\n",
        "    transform = T.Compose(transforms)\n",
        "\n",
        "    # Load data\n",
        "    imagenet_a_dataset = torchvision.datasets.ImageFolder(root=imagenet_a, transform=transform)\n",
        "    return torch.utils.data.DataLoader(imagenet_a_dataset, 1, shuffle=True, num_workers=8)"
      ],
      "metadata": {
        "id": "ut7hOuKqfnct"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_image(model: ViTForImageClassification, img: torch.Tensor) -> tuple[dict, dict]:\n",
        "\n",
        "    # Use GPU if available\n",
        "    img = img.to(DEVICE)\n",
        "\n",
        "    # Perform inference\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "\n",
        "    # Extract probabilities from model's output logits\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1).squeeze()\n",
        "\n",
        "    labels = load_model_labels()\n",
        "    results = {}\n",
        "\n",
        "    for index, probability in enumerate(probabilities):\n",
        "        results[index] = {\n",
        "            \"index\": index,\n",
        "            \"label\": labels[index],\n",
        "            \"probability\": probability.item()\n",
        "        }\n",
        "\n",
        "    predicted = probabilities.argmax(-1).item()\n",
        "    predicted = {\n",
        "        \"index\": predicted,\n",
        "        \"label\": labels[predicted],\n",
        "        \"probability\": probabilities[predicted].item()\n",
        "    }\n",
        "\n",
        "    return predicted, results"
      ],
      "metadata": {
        "id": "Bk0WB8NHXXlQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model (only once)\n",
        "model = load_model()\n",
        "\n",
        "# Load data (only once)\n",
        "data_loader = load_dataset()\n",
        "\n",
        "# Extract merged labels\n",
        "merged_labels = merge_labels()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SRcSAf9IJEv",
        "outputId": "6f4238c6-0cb2-4d85-89e8-0020a548d013"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model (Accuracy: 18.37 %)\n",
        "# accuracy = 0\n",
        "\n",
        "# for index, img in enumerate(data_loader):\n",
        "\n",
        "#     # Get model prediction\n",
        "#     predicted, results = classify_image(model=model, img=img[0])\n",
        "\n",
        "#     # Check if the predicted label exists inside the dataset labels\n",
        "#     if predicted[\"label\"] in merged_labels:\n",
        "\n",
        "#         merged_label = merged_labels[predicted[\"label\"]]\n",
        "\n",
        "#         # Check if the prediction was correct\n",
        "#         if merged_label[\"imagenet-a\"] == img[1].item():\n",
        "#             accuracy = accuracy + 1\n",
        "\n",
        "#     print(f\"Image {index+1} / {len(data_loader)} | Accuracy: {round((accuracy / (index + 1)) * 100, 2)}% ({accuracy} / {index + 1})\")\n",
        "\n",
        "# accuracy = accuracy / len(data_loader)"
      ],
      "metadata": {
        "id": "jrXGkChUYXHS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MEMO\n",
        "\n",
        "data_loader = load_dataset(resize=False)\n",
        "\n",
        "add_augmentation = lambda transformations: T.Compose(transformations)\n",
        "\n",
        "augmentations = [\n",
        "    add_augmentation([T.RandomCrop((100, 100)), T.Resize(SIZE)]),\n",
        "    add_augmentation([v2.RandomChannelPermutation(), T.Resize(SIZE)])\n",
        "]\n",
        "\n",
        "augmentations = [\n",
        "    T.CenterCrop((192, 192)),\n",
        "    v2.RandomRotation((0, 360)),\n",
        "    v2.RandomChannelPermutation(),\n",
        "    v2.RandomGrayscale(),\n",
        "    v2.RandomAutocontrast(),\n",
        "    v2.RandomPerspective()\n",
        "]\n",
        "\n",
        "for index, img in enumerate(data_loader):\n",
        "\n",
        "    augmentation = T.Compose([\n",
        "        v2.RandomOrder(augmentations),\n",
        "        T.Resize(SIZE)\n",
        "    ])\n",
        "\n",
        "    processed_img = img[0].detach().clone()\n",
        "    processed_img = augmentation(processed_img)\n",
        "\n",
        "    torchvision.utils.save_image(processed_img, \"test.png\")\n",
        "    # Get model prediction\n",
        "    predicted, results = classify_image(model=model, img=processed_img)\n",
        "\n",
        "    input()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG_vzyF3_8-o",
        "outputId": "0ad17f01-4f72-4df7-ea99-716d1ecf775a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = v2.RandomChoice([v2.RandomEqualize])\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R1zzSMKRPpq",
        "outputId": "d117702c-e8f5-4cbc-cefa-74407d96ce79"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomChoice(transforms=[<class 'torchvision.transforms.v2._color.RandomEqualize'>], p=[1.0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMPsCt88QG7U",
        "outputId": "06a251d7-359a-444a-95f4-76e9de70690c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AugMix',\n",
              " 'AutoAugment',\n",
              " 'AutoAugmentPolicy',\n",
              " 'CenterCrop',\n",
              " 'ClampBoundingBoxes',\n",
              " 'ColorJitter',\n",
              " 'Compose',\n",
              " 'ConvertBoundingBoxFormat',\n",
              " 'ConvertImageDtype',\n",
              " 'CutMix',\n",
              " 'ElasticTransform',\n",
              " 'FiveCrop',\n",
              " 'GaussianBlur',\n",
              " 'Grayscale',\n",
              " 'Identity',\n",
              " 'InterpolationMode',\n",
              " 'JPEG',\n",
              " 'Lambda',\n",
              " 'LinearTransformation',\n",
              " 'MixUp',\n",
              " 'Normalize',\n",
              " 'PILToTensor',\n",
              " 'Pad',\n",
              " 'RGB',\n",
              " 'RandAugment',\n",
              " 'RandomAdjustSharpness',\n",
              " 'RandomAffine',\n",
              " 'RandomApply',\n",
              " 'RandomAutocontrast',\n",
              " 'RandomChannelPermutation',\n",
              " 'RandomChoice',\n",
              " 'RandomCrop',\n",
              " 'RandomEqualize',\n",
              " 'RandomErasing',\n",
              " 'RandomGrayscale',\n",
              " 'RandomHorizontalFlip',\n",
              " 'RandomInvert',\n",
              " 'RandomIoUCrop',\n",
              " 'RandomOrder',\n",
              " 'RandomPerspective',\n",
              " 'RandomPhotometricDistort',\n",
              " 'RandomPosterize',\n",
              " 'RandomResize',\n",
              " 'RandomResizedCrop',\n",
              " 'RandomRotation',\n",
              " 'RandomShortestSize',\n",
              " 'RandomSolarize',\n",
              " 'RandomVerticalFlip',\n",
              " 'RandomZoomOut',\n",
              " 'Resize',\n",
              " 'SanitizeBoundingBoxes',\n",
              " 'ScaleJitter',\n",
              " 'TenCrop',\n",
              " 'ToDtype',\n",
              " 'ToImage',\n",
              " 'ToPILImage',\n",
              " 'ToPureTensor',\n",
              " 'ToTensor',\n",
              " 'Transform',\n",
              " 'TrivialAugmentWide',\n",
              " 'UniformTemporalSubsample',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_augment',\n",
              " '_auto_augment',\n",
              " '_color',\n",
              " '_container',\n",
              " '_deprecated',\n",
              " '_geometry',\n",
              " '_meta',\n",
              " '_misc',\n",
              " '_temporal',\n",
              " '_transform',\n",
              " '_type_conversion',\n",
              " '_utils',\n",
              " 'functional']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTi4RGIoO61B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}