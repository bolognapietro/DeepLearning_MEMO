{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaA4ccjTR4uV",
        "outputId": "ec23786d-181d-463f-e4f4-218b31eadc14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'dataset': No such file or directory\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V\n",
            "From (redirected): https://drive.google.com/uc?id=111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V&confirm=t&uuid=8de90087-d64b-4d1e-b2c8-fd5aca440cc8\n",
            "To: /content/imagenet-a.tar\n",
            "100% 688M/688M [00:05<00:00, 123MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Init workspace\n",
        "!rm -r dataset\n",
        "!mkdir dataset\n",
        "\n",
        "# Download dataset and extract it\n",
        "!gdown 111HiEoEvZDdg1Y2EefI6n5dA_p4sMV4V\n",
        "!mv imagenet-a.tar ./dataset\n",
        "!tar -xf ./dataset/imagenet-a.tar\n",
        "!mv imagenet-a ./dataset\n",
        "\n",
        "# Cleanup\n",
        "!rm ./dataset/imagenet-a.tar\n",
        "\n",
        "# (optional) Upgrading pytorch for the latest augmentation functions\n",
        "#!pip install --upgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUzDPvD_e8Fq",
        "outputId": "26abfc84-ffca-4850-b7cc-ce2e26a51477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1WKQGHjHUkIwZT0P2TpU9h-lY-6CnrsDd\n",
            "From (redirected): https://drive.google.com/uc?id=1WKQGHjHUkIwZT0P2TpU9h-lY-6CnrsDd&confirm=t&uuid=9b61578a-3aae-4ed0-8156-c6203c75af93\n",
            "To: /content/imagenetv2-matched-frequency.tar.gz\n",
            "100% 1.26G/1.26G [00:09<00:00, 127MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Init workspace\n",
        "!rm -r dataset\n",
        "!mkdir dataset\n",
        "\n",
        "# Download dataset and extract it\n",
        "!gdown 1WKQGHjHUkIwZT0P2TpU9h-lY-6CnrsDd\n",
        "!mv imagenetv2-matched-frequency.tar.gz ./dataset\n",
        "!tar -xf ./dataset/imagenetv2-matched-frequency.tar.gz\n",
        "!mv imagenetv2-matched-frequency-format-val ./dataset\n",
        "\n",
        "# Cleanup\n",
        "!rm ./dataset/imagenetv2-matched-frequency.tar.gz\n",
        "\n",
        "# (optional) Upgrading pytorch for the latest augmentation functions\n",
        "#!pip install --upgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ECdvhkFCpxci"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import basename, isfile, join\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from contextlib import nullcontext\n",
        "from copy import deepcopy\n",
        "from typing import Union\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import v2\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xMgaZ3ON9hNd"
      },
      "outputs": [],
      "source": [
        "# Use cuda if available\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pOveYdeygYdb"
      },
      "outputs": [],
      "source": [
        "def load_imagenet_v2_labels() -> list[int]:\n",
        "\n",
        "    imagenet_v2 = \"./dataset/imagenetv2-matched-frequency-format-val\"\n",
        "\n",
        "    labels = [int(f) for f in listdir(imagenet_v2) if not isfile(join(imagenet_v2, f))]\n",
        "    labels.sort()\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "scjsACtS7Mzz"
      },
      "outputs": [],
      "source": [
        "def load_model_labels() -> list[str]:\n",
        "\n",
        "    url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
        "    path = Path(basename(url))\n",
        "\n",
        "    # Check if labels file already exists\n",
        "    if not path.exists():\n",
        "        response = requests.get(url)\n",
        "        path.write_text(response.text)\n",
        "\n",
        "    # Load labels\n",
        "    with open(path, \"r\") as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mZ4Mo02l8cqQ"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name: str = \"google/vit-base-patch16-224\") -> ViTForImageClassification:\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    return ViTForImageClassification.from_pretrained(model_name).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X5w5Qab7nSxW"
      },
      "outputs": [],
      "source": [
        "class ImageNetV2(torch.utils.data.Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = load_imagenet_v2_labels() * 10\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        label = idx // 10\n",
        "\n",
        "        img_folder = os.path.join(self.img_dir, str(label))\n",
        "        img_path = [join(img_folder, f) for f in listdir(img_folder) if isfile(join(img_folder, f))][idx % (label if label != 0 else 1) - 1]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ut7hOuKqfnct"
      },
      "outputs": [],
      "source": [
        "def load_dataset(resize: bool = True) -> torch.utils.data.dataloader.DataLoader:\n",
        "\n",
        "    imagenet_v2 = \"./dataset/imagenetv2-matched-frequency-format-val\"\n",
        "\n",
        "    # Prepare data transformations for the train loader\n",
        "    transforms = [] if not resize else [T.Resize(SIZE)]\n",
        "    transforms.append(T.ToTensor())\n",
        "    transform = T.Compose(transforms)\n",
        "\n",
        "    # Load data\n",
        "    imagenet_v2_dataset = ImageNetV2(annotations_file=[], img_dir=imagenet_v2, transform=transform)\n",
        "    return torch.utils.data.DataLoader(imagenet_v2_dataset, 1, shuffle=True, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bk0WB8NHXXlQ"
      },
      "outputs": [],
      "source": [
        "def classify(model: ViTForImageClassification, img: torch.Tensor, no_grad: bool = True) -> dict:\n",
        "\n",
        "    # Use GPU if available\n",
        "    img = img.to(DEVICE)\n",
        "\n",
        "    # Perform inference\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad() if no_grad else nullcontext():\n",
        "        outputs = model(img)\n",
        "\n",
        "    # Extract probabilities from model's output logits\n",
        "    results = torch.nn.functional.softmax(outputs.logits, dim=-1).squeeze()\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iLeoCaOmWG2u"
      },
      "outputs": [],
      "source": [
        "def elaborate_results(results: torch.Tensor) -> Union[dict, list]:\n",
        "\n",
        "    # Load model's labels\n",
        "    model_labels = load_model_labels()\n",
        "\n",
        "    if len(results.shape) == 1:\n",
        "        results = [results]\n",
        "\n",
        "    # Process results\n",
        "    final_results = []\n",
        "\n",
        "    for result in results:\n",
        "\n",
        "        item_results = {\n",
        "            \"predicted\": {},\n",
        "            \"results\": {}\n",
        "        }\n",
        "\n",
        "        predicted = None\n",
        "\n",
        "        for index, probability in enumerate(result):\n",
        "\n",
        "            item_results[\"results\"][index] = {\n",
        "                \"index\": index,\n",
        "                \"label\": model_labels[index],\n",
        "                \"probability\": probability.item()\n",
        "            }\n",
        "\n",
        "            if predicted is None or predicted[\"probability\"] < probability.item():\n",
        "                predicted = item_results[\"results\"][index]\n",
        "\n",
        "        item_results[\"predicted\"] = predicted\n",
        "\n",
        "        final_results.append(item_results)\n",
        "\n",
        "    return final_results if len(final_results) > 1 else final_results[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrXGkChUYXHS"
      },
      "outputs": [],
      "source": [
        "# # Load model (only once)\n",
        "# model = load_model()\n",
        "\n",
        "# # Load data (only once)\n",
        "# data_loader = load_dataset()\n",
        "\n",
        "# # Evaluate the model (Accuracy: 18.37 %)\n",
        "# accuracy = 0\n",
        "\n",
        "# for index, img in enumerate(data_loader):\n",
        "\n",
        "#     # Get model prediction\n",
        "#     results = classify(model=model, img=img[0])\n",
        "#     results = elaborate_results(results=results)\n",
        "#     predicted, results = results[\"predicted\"], results[\"results\"]\n",
        "\n",
        "#     if img[1].item() == predicted[\"index\"]:\n",
        "#         accuracy = accuracy + 1\n",
        "\n",
        "#     print(f\"Image {index+1} / {len(data_loader)} | Accuracy: {round((accuracy / (index + 1)) * 100, 2)}% ({accuracy} / {index + 1})\")\n",
        "\n",
        "# accuracy = accuracy / len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_image(img):\n",
        "  plt.imshow(img.squeeze(0).permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "rpjtSheX9NJo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "AUGMENTATIONS\n",
        "\"\"\"\n",
        "\n",
        "import skimage as sk\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from PIL import Image as PILImage\n",
        "import cv2\n",
        "from scipy.ndimage import zoom as scizoom\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\"\"\"helper for zoom_blur\"\"\"\n",
        "def clipped_zoom(img, zoom_factor):\n",
        "    h = img.shape[0]\n",
        "    # ceil crop height(= crop width)\n",
        "    ch = int(np.ceil(h / zoom_factor))\n",
        "\n",
        "    top = (h - ch) // 2\n",
        "    img = scizoom(img[top:top + ch, top:top + ch], (zoom_factor, zoom_factor, 1), order=1)\n",
        "    # trim off any extra pixels\n",
        "    trim_top = (img.shape[0] - h) // 2\n",
        "\n",
        "    return img[trim_top:trim_top + h, trim_top:trim_top + h]\n",
        "\n",
        "\"\"\"helper for defocus_blur\"\"\"\n",
        "def disk(radius, alias_blur=0.1, dtype=np.float32):\n",
        "    if radius <= 8:\n",
        "        L = np.arange(-8, 8 + 1)\n",
        "        ksize = (3, 3)\n",
        "    else:\n",
        "        L = np.arange(-radius, radius + 1)\n",
        "        ksize = (5, 5)\n",
        "    X, Y = np.meshgrid(L, L)\n",
        "    aliased_disk = np.array((X ** 2 + Y ** 2) <= radius ** 2, dtype=dtype)\n",
        "    aliased_disk /= np.sum(aliased_disk)\n",
        "\n",
        "    # supersample disk to antialias\n",
        "    return cv2.GaussianBlur(aliased_disk, ksize=ksize, sigmaX=alias_blur)\n",
        "\n",
        "def saturate(x, severity=1):\n",
        "    c = [(0.3, 0), (0.1, 0), (2, 0), (5, 0.1), (20, 0.2)][severity - 1]\n",
        "\n",
        "    x = np.array(x) / 255.\n",
        "    x = sk.color.rgb2hsv(x)\n",
        "    x[:, :, 1] = np.clip(x[:, :, 1] * c[0] + c[1], 0, 1)\n",
        "    x = sk.color.hsv2rgb(x)\n",
        "\n",
        "    return np.clip(x, 0, 1) * 255\n",
        "\n",
        "\n",
        "def pixelate(x, severity=1):\n",
        "    c = [0.6, 0.5, 0.4, 0.3, 0.25][severity - 1]\n",
        "\n",
        "    x = x.resize((int(IMG_SIZE * c), int(IMG_SIZE * c)), PILImage.BOX)\n",
        "    x = x.resize((IMG_SIZE, IMG_SIZE), PILImage.BOX)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def jpeg_compression(x, severity=1):\n",
        "    c = [25, 18, 15, 10, 7][severity - 1]\n",
        "\n",
        "    output = BytesIO()\n",
        "    x.save(output, 'JPEG', quality=c)\n",
        "    x = PILImage.open(output)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def brightness(x, severity=1):\n",
        "    c = [.1, .2, .3, .4, .5][severity - 1]\n",
        "\n",
        "    x = np.array(x) / 255.\n",
        "    x = sk.color.rgb2hsv(x)\n",
        "    x[:, :, 2] = np.clip(x[:, :, 2] + c, 0, 1)\n",
        "    x = sk.color.hsv2rgb(x)\n",
        "\n",
        "    return np.clip(x, 0, 1) * 255\n",
        "\n",
        "\n",
        "def zoom_blur(x, severity=1):\n",
        "    c = [np.arange(1, 1.11, 0.01),\n",
        "         np.arange(1, 1.16, 0.01),\n",
        "         np.arange(1, 1.21, 0.02),\n",
        "         np.arange(1, 1.26, 0.02),\n",
        "         np.arange(1, 1.31, 0.03)][severity - 1]\n",
        "\n",
        "    x = (np.array(x) / 255.).astype(np.float32)\n",
        "    out = np.zeros_like(x)\n",
        "    for zoom_factor in c:\n",
        "        zoomed = clipped_zoom(x, zoom_factor)\n",
        "        resized_zoomed = cv2.resize(zoomed, (out.shape[1], out.shape[0]))\n",
        "        out += resized_zoomed\n",
        "\n",
        "    x = (x + out) / (len(c) + 1)\n",
        "    return np.clip(x, 0, 1) * 255\n",
        "\n",
        "\n",
        "def defocus_blur(x, severity=1):\n",
        "    c = [(3, 0.1), (4, 0.5), (6, 0.5), (8, 0.5), (10, 0.5)][severity - 1]\n",
        "\n",
        "    x = np.array(x) / 255.\n",
        "    kernel = disk(radius=c[0], alias_blur=c[1])\n",
        "\n",
        "    channels = []\n",
        "    for d in range(3):\n",
        "        channels.append(cv2.filter2D(x[:, :, d], -1, kernel))\n",
        "    channels = np.array(channels).transpose((1, 2, 0))  # 3x224x224 -> 224x224x3\n",
        "\n",
        "    return np.clip(channels, 0, 1) * 255\n",
        "\n",
        "\n",
        "def gaussian_noise(x, severity=1):\n",
        "    c = [.08, .12, 0.18, 0.26, 0.38][severity - 1]\n",
        "\n",
        "    x = np.array(x) / 255.\n",
        "    return np.clip(x + np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n",
        "\n",
        "\n",
        "def shot_noise(x, severity=1):\n",
        "    c = [60, 25, 12, 5, 3][severity - 1]\n",
        "\n",
        "    x = np.array(x) / 255.\n",
        "    return np.clip(np.random.poisson(x * c) / c, 0, 1) * 255\n",
        "\n",
        "def impulse_noise(x, severity=1):\n",
        "    c = [.03, .06, .09, 0.17, 0.27][severity - 1]\n",
        "\n",
        "    x = sk.util.random_noise(np.array(x) / 255., mode='s&p', amount=c)\n",
        "    return np.clip(x, 0, 1) * 255\n",
        "\n",
        "def speckle_noise(x, severity=1):\n",
        "    c = [.15, .2, 0.35, 0.45, 0.6][severity - 1]\n",
        "\n",
        "    x = np.array(x) / 255.\n",
        "    return np.clip(x + x * np.random.normal(size=x.shape, scale=c), 0, 1) * 255"
      ],
      "metadata": {
        "id": "4J0hHXdRfuOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(img, augmentation_function, severity):\n",
        "  img = img * 255\n",
        "  img = img.to(torch.uint8)\n",
        "\n",
        "  img_np = img.numpy().transpose(0, 2, 3, 1)\n",
        "  augmented_np = augmentation_function(img_np, severity=severity)\n",
        "\n",
        "  augmented_tensor = torch.tensor(augmented_np, dtype=torch.uint8).permute(0, 3, 1, 2)\n",
        "  return augmented_tensor"
      ],
      "metadata": {
        "id": "NUkOrsxSf4mT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708,
          "referenced_widgets": [
            "d5ad4988bf7141f488552ce2fdd3b60c",
            "939e821dcbca4063ab73073351a1a402",
            "9c638fb779a94d489e49e5bd0492c60d",
            "c6bcaf2db5e249379b32f45b6889eeaf",
            "292feaec246f476e8c49e1d54289f5a6",
            "8d61724ec93c4d4081afe4dd2ffff4ee",
            "35ca1003ab474914ac4d28795178b8b8",
            "b089be1699314502956b542796954fa6",
            "106abb79310c4a9593420b71f5677259",
            "e860c1166bac4b6482f3603833190e07",
            "41bb2ea4d8ef4907b8c8ec0db17bf4ab",
            "8eb09ac588874e0592540b8ccdf66754",
            "4cbef4cfa9114357adbb773e0864267c",
            "e9f4e7b7dba7478c9117b0c838a2a86f",
            "0d63e20e7c824831a472b407c7a880aa",
            "c145a930f8a4474a9cc4514d7ef7de7a",
            "ff02137725834f5786136cd38aeaa284",
            "d06f3078a9e9468b9846da2ca50dc6ff",
            "dfe64d47a5b145ac8e0ea21a23268dcf",
            "5ff9becc733a4899882bc098b3d37b0c",
            "55004a91627349ee94af8b9ea92aedcb",
            "50b5557af0a54c4d963e7ce9b149c45d"
          ]
        },
        "id": "IzaEQC-_dzji",
        "outputId": "d7bd3e41-c37a-4fcd-991b-9e453b292c64"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5ad4988bf7141f488552ce2fdd3b60c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eb09ac588874e0592540b8ccdf66754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1 / 10000 | Accuracy before: 100.0% (1 / 1) | Accuracy after: 100.0% (1 / 1) | Diff: 0.0%\n",
            "Image 2 / 10000 | Accuracy before: 100.0% (2 / 2) | Accuracy after: 100.0% (2 / 2) | Diff: 0.0%\n",
            "Image 3 / 10000 | Accuracy before: 66.7% (2 / 3) | Accuracy after: 100.0% (3 / 3) | Diff: 33.33%\n",
            "Image 4 / 10000 | Accuracy before: 75.0% (3 / 4) | Accuracy after: 100.0% (4 / 4) | Diff: 25.0%\n",
            "Image 5 / 10000 | Accuracy before: 80.0% (4 / 5) | Accuracy after: 100.0% (5 / 5) | Diff: 20.0%\n",
            "Image 6 / 10000 | Accuracy before: 66.7% (4 / 6) | Accuracy after: 83.3% (5 / 6) | Diff: 16.67%\n",
            "Image 7 / 10000 | Accuracy before: 71.4% (5 / 7) | Accuracy after: 85.7% (6 / 7) | Diff: 14.29%\n",
            "Image 8 / 10000 | Accuracy before: 75.0% (6 / 8) | Accuracy after: 87.5% (7 / 8) | Diff: 12.5%\n",
            "Image 9 / 10000 | Accuracy before: 77.8% (7 / 9) | Accuracy after: 88.9% (8 / 9) | Diff: 11.11%\n",
            "Image 10 / 10000 | Accuracy before: 80.0% (8 / 10) | Accuracy after: 90.0% (9 / 10) | Diff: 10.0%\n",
            "Image 11 / 10000 | Accuracy before: 72.7% (8 / 11) | Accuracy after: 81.8% (9 / 11) | Diff: 9.09%\n",
            "Image 12 / 10000 | Accuracy before: 66.7% (8 / 12) | Accuracy after: 75.0% (9 / 12) | Diff: 8.33%\n",
            "Image 13 / 10000 | Accuracy before: 61.5% (8 / 13) | Accuracy after: 69.2% (9 / 13) | Diff: 7.69%\n",
            "Image 14 / 10000 | Accuracy before: 64.3% (9 / 14) | Accuracy after: 71.4% (10 / 14) | Diff: 7.14%\n",
            "Image 15 / 10000 | Accuracy before: 66.7% (10 / 15) | Accuracy after: 73.3% (11 / 15) | Diff: 6.67%\n",
            "Image 16 / 10000 | Accuracy before: 68.8% (11 / 16) | Accuracy after: 75.0% (12 / 16) | Diff: 6.25%\n",
            "Image 17 / 10000 | Accuracy before: 70.6% (12 / 17) | Accuracy after: 76.5% (13 / 17) | Diff: 5.88%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e17a78203070>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Classificazione dell'immagine 1 dopo le augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melaborate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e6c16bee0796>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(model, img, no_grad)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Use GPU if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Perform inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Supponendo che load_dataset, classify_image, merged_labels e il modello siano definiti altrove\n",
        "accuracy_before = 0\n",
        "accuracy_after = 0\n",
        "\n",
        "# Load model (only once)\n",
        "model = load_model()\n",
        "original_model = deepcopy(model)\n",
        "\n",
        "data_loader = load_dataset(resize=False)\n",
        "\n",
        "# transformation = T.Compose([\n",
        "#         T.Resize((500, 500)),\n",
        "#         T.CenterCrop((384, 384)) ])\n",
        "\n",
        "transforms = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=SIZE, antialias=True),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "resize_transformation = T.Compose([ T.Resize(SIZE) ])\n",
        "\n",
        "# Salva lo stato iniziale del modello\n",
        "initial_state = model.state_dict().copy()\n",
        "\n",
        "for index, img in enumerate(data_loader):\n",
        "    # Ripristina lo stato iniziale del modello\n",
        "    model = deepcopy(original_model)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    # Azzera i gradienti prima di calcolare i nuovi\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Immagine ridimensionata (384x384)\n",
        "    img1 = resize_transformation(img[0])\n",
        "    # Immagini con augmentation\n",
        "    img2 = transforms(img[0])\n",
        "    img3 = transforms(img[0])\n",
        "    img4 = transforms(img[0])\n",
        "\n",
        "    # Concatena immagini\n",
        "    imgs = [img1, img2, img3, img4]\n",
        "    input = torch.cat(imgs, dim=0)\n",
        "\n",
        "    # Classificazione dell'immagine 1 prima delle augmentation\n",
        "    results = classify(model=model, img=img1)\n",
        "    results = elaborate_results(results=results)\n",
        "    predicted, results = results[\"predicted\"], results[\"results\"]\n",
        "\n",
        "    # Aggiorna accuracy della classificazione senza augmentation\n",
        "    if img[1].item() == predicted[\"index\"]:\n",
        "        accuracy_before = accuracy_before + 1\n",
        "\n",
        "    predicted_before = predicted[\"label\"]\n",
        "\n",
        "    # Calcola gli output delle immagini\n",
        "    output = model(input.to(DEVICE))\n",
        "\n",
        "    # Combina le probabilità delle immagini\n",
        "    probabilities = torch.nn.functional.softmax(output.logits, dim=-1).squeeze().to(DEVICE)\n",
        "\n",
        "    # Calcolo entropia\n",
        "    marginal = torch.mean(probabilities, dim=0).to(DEVICE)\n",
        "    entropy = -torch.sum(marginal * torch.log(marginal)).to(DEVICE)\n",
        "    entropy.backward()\n",
        "\n",
        "    # Gradient step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Classificazione dell'immagine 1 dopo le augmentation\n",
        "    results = classify(model=model, img=img1)\n",
        "    results = elaborate_results(results=results)\n",
        "    predicted, results = results[\"predicted\"], results[\"results\"]\n",
        "\n",
        "    #print(probabilities1 == probabilities2)\n",
        "    # Aggiorna accuracy della classificazione con augmentation\n",
        "    if img[1].item() == predicted[\"index\"]:\n",
        "        accuracy_after = accuracy_after + 1\n",
        "\n",
        "    label1 = f\"Image {index + 1} / {len(data_loader)}\"\n",
        "    label2 = f\"Accuracy before: {round((accuracy_before / (index + 1)) * 100, 1)}% ({accuracy_before} / {index + 1})\"\n",
        "    label3 = f\"Accuracy after: {round((accuracy_after / (index + 1)) * 100, 1)}% ({accuracy_after} / {index + 1})\"\n",
        "    label4 = f\"Diff: {round((accuracy_after / (index + 1)) * 100 - (accuracy_before / (index + 1)) * 100, 2)}%\"\n",
        "\n",
        "    print(f\"{label1} | {label2} | {label3} | {label4}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5ad4988bf7141f488552ce2fdd3b60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_939e821dcbca4063ab73073351a1a402",
              "IPY_MODEL_9c638fb779a94d489e49e5bd0492c60d",
              "IPY_MODEL_c6bcaf2db5e249379b32f45b6889eeaf"
            ],
            "layout": "IPY_MODEL_292feaec246f476e8c49e1d54289f5a6"
          }
        },
        "939e821dcbca4063ab73073351a1a402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d61724ec93c4d4081afe4dd2ffff4ee",
            "placeholder": "​",
            "style": "IPY_MODEL_35ca1003ab474914ac4d28795178b8b8",
            "value": "config.json: 100%"
          }
        },
        "9c638fb779a94d489e49e5bd0492c60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b089be1699314502956b542796954fa6",
            "max": 69665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_106abb79310c4a9593420b71f5677259",
            "value": 69665
          }
        },
        "c6bcaf2db5e249379b32f45b6889eeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e860c1166bac4b6482f3603833190e07",
            "placeholder": "​",
            "style": "IPY_MODEL_41bb2ea4d8ef4907b8c8ec0db17bf4ab",
            "value": " 69.7k/69.7k [00:00&lt;00:00, 3.65MB/s]"
          }
        },
        "292feaec246f476e8c49e1d54289f5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d61724ec93c4d4081afe4dd2ffff4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ca1003ab474914ac4d28795178b8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b089be1699314502956b542796954fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106abb79310c4a9593420b71f5677259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e860c1166bac4b6482f3603833190e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bb2ea4d8ef4907b8c8ec0db17bf4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eb09ac588874e0592540b8ccdf66754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cbef4cfa9114357adbb773e0864267c",
              "IPY_MODEL_e9f4e7b7dba7478c9117b0c838a2a86f",
              "IPY_MODEL_0d63e20e7c824831a472b407c7a880aa"
            ],
            "layout": "IPY_MODEL_c145a930f8a4474a9cc4514d7ef7de7a"
          }
        },
        "4cbef4cfa9114357adbb773e0864267c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff02137725834f5786136cd38aeaa284",
            "placeholder": "​",
            "style": "IPY_MODEL_d06f3078a9e9468b9846da2ca50dc6ff",
            "value": "model.safetensors: 100%"
          }
        },
        "e9f4e7b7dba7478c9117b0c838a2a86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe64d47a5b145ac8e0ea21a23268dcf",
            "max": 346293852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ff9becc733a4899882bc098b3d37b0c",
            "value": 346293852
          }
        },
        "0d63e20e7c824831a472b407c7a880aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55004a91627349ee94af8b9ea92aedcb",
            "placeholder": "​",
            "style": "IPY_MODEL_50b5557af0a54c4d963e7ce9b149c45d",
            "value": " 346M/346M [00:01&lt;00:00, 259MB/s]"
          }
        },
        "c145a930f8a4474a9cc4514d7ef7de7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff02137725834f5786136cd38aeaa284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06f3078a9e9468b9846da2ca50dc6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfe64d47a5b145ac8e0ea21a23268dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff9becc733a4899882bc098b3d37b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55004a91627349ee94af8b9ea92aedcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b5557af0a54c4d963e7ce9b149c45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}